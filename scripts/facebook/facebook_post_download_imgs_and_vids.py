'''
# Download Facebook post's images and videos
# This script will download all the images and videos of all posts inside a given JSON file 
# Last updated: 2021-09-22
'''

import logging, os, urllib.parse
from datetime import datetime
from urllib.request import HTTPError

import pandas as pd, emoji

from facebook_scraper import *
from progressist import ProgressBar

filename = os.path.basename(__file__)
filename = filename.replace('.py','')

logger = logging.getLogger()
logger.setLevel(logging.DEBUG)

formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

now_as_string = datetime.now().strftime('%Y%m%d_%H%M')

if not os.path.exists(f'logs/{filename}'):
	os.makedirs(f'logs/{filename}')
file_handler = logging.FileHandler(f'logs/{filename}/{filename}_log_{now_as_string}.txt')
file_handler.setLevel(logging.DEBUG)
logger.addHandler(file_handler)
file_handler.setFormatter(formatter)

stream_handler = logging.StreamHandler()
logger.addHandler(stream_handler)
stream_handler.setFormatter(formatter)

# ============================================
# Helper functions
def get_input_variables():
	while True:
		try:
			username = input("Enter username of FB profile you want to download:\n")
			json_file_path = input("\nEnter path to JSON file containing posts. Your JSON file MUST have been pulled within 12-24 hours of running this script (otherwise downloading will not work).\n(Ex: C:/users/hk/Desktop/fb_posts_standnews_20210614_0435.txt\nThis JSON file is generated by facebook_post_scraper.py file. Script will download all the images and videos, of the posts contained in JSON file.\n")

		except ValueError as e:
			print("Invalid input! Try again!")
			continue

		return_dict = {
			'username': username,
			'json_file_path': json_file_path,
		}
		return return_dict 

def remove_emoji_newline(text, num_characters_to_keep):
	# emoji, from https://stackoverflow.com/a/61018246/
	stripped_text = emoji.get_emoji_regexp().sub("", text) 
	
	# newline and other characters
	stripped_text = stripped_text.replace('\n','') 
	stripped_text = stripped_text.replace('/','')
	stripped_text = stripped_text.replace('\\','')

	# only keep set # of characters
	stripped_text = stripped_text[0:num_characters_to_keep]

	return stripped_text


def media_download(username, filename_of_json_file):
	with open(filename_of_json_file) as f:
		json_obj = json.load(f)

	# Create "media" folder if it does not exist
	if not os.path.exists(f'posts/{username}/media'):
		os.makedirs(f'posts/{username}/media')

	post_counter = 0
	for post in json_obj:
		post_id = post['post_id']

		post_counter += 1
		media_exists = False
		logger.info(f'Processing post #{post_counter} - Post ID: {post_id} - Date: {post["time"]}')

		# Save files in its own folder
		# ==========================
		# replace ":" character in timezone offset, so that strptime can interpret time correctly
		if ":" == post["time"][-3:-2]:
			post_time_as_text = post["time"][:-3] + post["time"][-2:]

		post_time_as_text = datetime.strptime(post_time_as_text, "%Y-%m-%d %H:%M:%S%z").strftime('%Y%m%d_%H%M')
		# We don't want folder name to have emojis or newlines
		folder_name = f'posts/{username}/media/{post_time_as_text}_{post_id}_{remove_emoji_newline(post["text"],50)}'

		if not os.path.exists(folder_name):
			os.makedirs(folder_name)

		# If video exists, download video
		# ==========================
		if post['video'] is not None and post['video'].startswith('https://'):
			media_exists = True

			video_id = post['video_id']
			video_url = post['video']

			# Get file extension of url, from here: https://stackoverflow.com/a/4776959
			path = urllib.parse.urlparse(video_url).path
			ext = os.path.splitext(path)[1]

			# Download video
			bar = ProgressBar(template="Download |{animation}| {done:B}/{total:B} {percent} {elapsed} {tta} ")
			logger.info(f'Downloading post #{post_counter}, video {video_id}...')
			logger.debug(post['video'])
			try:
				urllib.request.urlretrieve(post['video'], f'{folder_name}/{post_id}_{video_id}{ext}', bar.on_urlretrieve)

			except HTTPError as e:
				logger.error(f'Cannot download video. Post ID: {post_id}. Video ID: {video_id}\nError code: {e.code}\nError: {e}')

		# If this post contains images, then download them. 
		# =========================
		# Check if "image_ids" json key exists
		img_counter = 0

		if 'image_ids' in post:
			if post['image_ids'] is not None:
				if len(post['image_ids']) >= 1:
					media_exists = True

					for image_id in post['image_ids']:		
						image_url = post['images'][img_counter]

						img_counter += 1
						logger.info(f'Downloading post #{post_counter}, image #{img_counter}, image id: {image_id}...')

						# Get file extension of url, from here: https://stackoverflow.com/a/4776959
						path = urllib.parse.urlparse(image_url).path
						ext = os.path.splitext(path)[1]

						try:
							urllib.request.urlretrieve(image_url, f'{folder_name}/{post_id}_{img_counter:02d}_{image_id}{ext}')
						except HTTPError as e:
							logger.error(f'Cannot download image. Post #{post_counter}, post ID: {post_id}, image #{img_counter}, image ID: {image_id}\nError code: {e.code}\nError: {e}')

		# Download low quality images:
		if len(post['images_lowquality']) >= 1:
			media_exists = True

			for img_lowquality_url in post['images_lowquality']:
				path = urllib.parse.urlparse(img_lowquality_url).path
				img_id = path.rsplit("/", 1)[-1]

				img_counter += 1
				logger.info(f'Downloading post #{post_counter}, image #{img_counter}, image id: {img_id}...')

				# Get file extension of url, from here: https://stackoverflow.com/a/4776959
				ext = os.path.splitext(path)[1]
				img_id = img_id.replace(ext,'') # replace extra extension in img_id

				try:						
					urllib.request.urlretrieve(img_lowquality_url, f'{folder_name}/{post_id}_{img_counter:02d}_{img_id}{ext}')
				except HTTPError as e:
					logger.error(f'Cannot download image. Post #{post_counter}, post ID: {post_id}, image #{img_counter}, Low quality img ID: {img_id}\nError code: {e.code}\nError: {e}')


		if media_exists == False:
			logger.info(f"No media for post #{post_id}")
			with open(f'{folder_name}/no_media_for_this_post.txt','w') as f:
				# create empty file named "no_media_for_this_post.txt" to indicate that this post has no media
				pass
	return

# ============================================
# Run script

input_variables = get_input_variables()

media_download(input_variables['username'], input_variables['json_file_path'])
